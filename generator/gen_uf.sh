(
    CUDA_VISIBLE_DEVICES=0 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 0  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen0.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=0 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 1  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen1.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=0 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 2  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen2.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=0 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 3  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen3.log 2>&1
) &
(
    CUDA_VISIBLE_DEVICES=1 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 4  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen4.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=1 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 5  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen5.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=1 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 6  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen6.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=1 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 7  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen7.log 2>&1
) &
(
    CUDA_VISIBLE_DEVICES=2 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 8  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen8.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=2 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 9  --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen9.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=2 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 10 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen10.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=2 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 11 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen11.log 2>&1
) &
(
    CUDA_VISIBLE_DEVICES=3 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 12 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen12.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=3 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 13 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen13.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=3 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 14 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen14.log 2>&1 ;
    CUDA_VISIBLE_DEVICES=3 nohup python3 spin/generate_vllm.py --model mistralai/Mistral-7B-v0.1 --revision 7231864981174d9bee8c7687c24c8344414eae6b --input_dir HuggingFaceH4/ultrafeedback_binarized --split train_sft --world_size 1 --chat --seed 15 --temp 0.7 --top_p 1.0 --top_k 50 --max_new_tokens 320 --system_message "You are an unhelpful assistant." --output_prefix mistral_ultrafeedback > gen15.log 2>&1
) &
wait